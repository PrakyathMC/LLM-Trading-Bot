ğŸ¤– LLM-Powered Financial Trading Bot
An intelligent trading assistant built with RAG (Retrieval-Augmented Generation) that analyzes financial documents and provides expert insights using OpenAI and AstraDB vector storage.


ğŸš€ Features

PDF Analysis: Processes financial documents and SEC filings
Intelligent Q&A: Context-aware responses using RAG architecture
Vector Search: Semantic search powered by AstraDB
Web Interface: Clean Flask-based chat UI
Cloud Ready: Deployed on AWS EC2

ğŸ› ï¸ Tech Stack

LLM Framework: LangChain + OpenAI GPT
Vector Database: DataStax AstraDB
Backend: Flask (Python)
Document Processing: PyPDF + RecursiveCharacterTextSplitter
Deployment: AWS EC2

ğŸ“‹ Prerequisites

Python 3.8+
OpenAI API Key
AstraDB Account
AWS Account (for deployment)



ğŸ”§ Installation

Clone the repository

## git clone https://github.com/PrakyathMC/LLM-Trading-Bot.git
## cd LLM-Trading-Bot

Create virtual environment

## python -m venv venv
## source venv/bin/activate  # On Windows: venv\Scripts\activate

Install dependencies

# pip install -r requirements.txt

Set up environment variables

# Create .env file
OPENAI_API_KEY=your_openai_key
ASTRA_DB_API_ENDPOINT=your_endpoint
ASTRA_DB_APPLICATION_TOKEN=your_token
ASTRA_DB_KEYSPACE=default_keyspace
ğŸ’» Usage

Run locally

python app.py

Access the application

http://localhost:5000

Ask financial questions


"What is the company's revenue for 2023?"
"Explain the risk factors"
"What are the main products?"

ğŸ—ï¸ Architecture
### PDF Documents â†’ LangChain Loader â†’ Text Chunking â†’ Vector Embeddings â†’ AstraDB â†“
### User Query â†’ Flask API â†’ Retriever â†’ LLM (GPT) â†’ Generated Response â† Context

ğŸ“ Project Structure
LLM-Trading-Bot/
â”œâ”€â”€ app.py                 # Flask application
â”œâ”€â”€ tradingbot/
â”‚   â”œâ”€â”€ data_ingestion.py  # Document processing & vector storage
â”‚   â”œâ”€â”€ retrieval_generation.py  # RAG chain setup
â”‚   â””â”€â”€ helper.py          # PDF loading utilities
â”œâ”€â”€ data/                  # Financial documents
â”œâ”€â”€ templates/             # HTML templates
â””â”€â”€ requirements.txt       # Python dependencies
# ğŸŒ AWS Deployment
# Deployed on AWS EC2 t3.large instance for optimal performance:

# Launch EC2 instance with security group (ports 22, 5000)
# Clone repository and install dependencies
# Configure environment variables
# Run with python app.py

ğŸ¯ Key Features Implemented

âœ… RAG pipeline with LangChain
âœ… Vector similarity search
âœ… Conversation context handling
âœ… Real-time Q&A interface
âœ… Cloud deployment ready

ğŸ“Š Performance

# Chunk Size: 500 characters with 100 overlap
# Retrieval: Top 3 most relevant chunks
# Response Time: ~2-3 seconds average


ğŸ‘¨â€ğŸ’» Author
Prakyath MC
AI/ML Engineer 
ğŸ“„ License
MIT License - feel free to use this project for learning!

## Note: This is a demonstration project for learning LLMOps concepts. Not intended for actual trading decisions.RetryClaude can make mistakes. Please double-check responses.